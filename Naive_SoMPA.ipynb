{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review the Polarising Impedance $Z_p$ and $E_crit$ adapted from new battery $Z_p$ as a prior and random degraded battery discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from ParticleFilter.Tools import resample\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_context('notebook')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Characterisation_Set = pickle.load(open(\"Battery_Data/new_battery_cycles/Characterisation_Set_Complete.p\", 'rb'))\n",
    "\n",
    "\n",
    "def scale(X):\n",
    "    \"\"\"\n",
    "\n",
    "    :param X:\n",
    "    :return: Normalised array like X, mean, std\n",
    "    \"\"\"\n",
    "    return (X - X.min())/(X.max() - X.min()), X.min(), X.max()\n",
    "\n",
    "\n",
    "def apply_scale(X, X_min, X_max):\n",
    "    \"\"\"\n",
    "\n",
    "    :param X:\n",
    "    :return: Normalised array like X, mean, std\n",
    "    \"\"\"\n",
    "    return (X - X_min)/(X_max - X_min)\n",
    "\n",
    "\n",
    "SoC, SoC_min, SoC_max = scale(Characterisation_Set[\"SoC\"].T)\n",
    "Current, Current_min, Current_max = scale(Characterisation_Set[\"Current\"].T)\n",
    "# Voltage, Voltage_min, Voltage_max = scale(Characterisation_Set[\"Voltage\"].T)\n",
    "Voltage = Characterisation_Set[\"Voltage\"].T\n",
    "Characterisation_Set[\"preprocessing\"] = {\n",
    "    \"SoC\": (SoC_max, SoC_min),\n",
    "    \"Current\": (Current_max, Current_min)\n",
    "}\n",
    "\n",
    "E_crit_new = 26267.160775850585\n",
    "E_crit_old = 21879.133773481735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNetwork, self).__init__()\n",
    "        self.Z_hl1 = nn.Linear(2, 1024)\n",
    "        self.Z_hl2 = nn.Linear(1024, 512)\n",
    "        self.Z_p = nn.Linear(512, 1)\n",
    "        self.E_crit = nn.Parameter(torch.Tensor([1.0]), requires_grad=True)\n",
    "        # SMC params\n",
    "        self.f_mean = torch.Tensor([0.0])\n",
    "        self.f_std = torch.Tensor([0.002])\n",
    "        self.g_std = 0.01\n",
    "        self.nu = torch.Tensor([1.0 / (self.g_std * np.sqrt(2 * np.pi))])\n",
    "        self.voltage_expected_hist = None\n",
    "        self.soc_expected_hist = None\n",
    "\n",
    "    def VoC(self, SoC):\n",
    "        v_L = torch.Tensor([[-1.59614486]]).to(device)\n",
    "        v_0 = torch.Tensor([[4.13646328]]).to(device)\n",
    "        gamma = torch.Tensor([[0.63726463]]).to(device)\n",
    "        alpha = torch.Tensor([[1.40174122]]).to(device)\n",
    "        beta = torch.Tensor([[2.54478965]]).to(device)\n",
    "        return v_L + (v_0 - v_L) * torch.exp(gamma * (SoC - 1)) + alpha * v_L * (SoC - 1) \\\n",
    "               + (1 - alpha) * v_L * (torch.exp(-beta) - torch.exp(-beta * torch.sqrt(SoC)))\n",
    "\n",
    "    def forward(self, soc_init, current, voltage_measured,  estimation_stop=None):\n",
    "        first = True\n",
    "        set_size = current.shape[1]\n",
    "        if estimation_stop is not None and estimation_stop <= set_size:\n",
    "            set_size = estimation_stop\n",
    "        voltage = torch.empty((soc_init.shape[0], set_size), dtype=torch.float)\n",
    "        soc_hist = torch.empty((soc_init.shape[0], set_size), dtype=torch.float)\n",
    "        self.w_hist = torch.empty((soc_init.shape[0], set_size), dtype=torch.float)\n",
    "        self.voltage_expected_hist = torch.empty((1, set_size), dtype=torch.float)\n",
    "        self.soc_expected_hist = torch.empty((1, set_size), dtype=torch.float)\n",
    "        soc = soc_init.to(device, torch.float)\n",
    "        N = soc_init.shape[0]\n",
    "\n",
    "        I = torch.ones(N, 1) * current[0, 0]\n",
    "        I = I.to(device, torch.float)\n",
    "        scaled_I = apply_scale(I, Current_min, Current_max)\n",
    "        scaled_soc = apply_scale(soc, SoC_min, SoC_max)\n",
    "        # Estimate Z_p\n",
    "        combined = torch.cat((scaled_soc, scaled_I), 1)\n",
    "        Z = torch.sigmoid(self.Z_hl1(combined))\n",
    "        Z = torch.sigmoid(self.Z_hl2(Z))\n",
    "        Z = self.Z_p(Z)\n",
    "\n",
    "        # Estimate prior V\n",
    "        V = self.VoC(soc) - I * Z\n",
    "        for t in range(set_size):\n",
    "\n",
    "            # Predict SoC\n",
    "            soc = soc - I*V/E_crit_new*self.E_crit\n",
    "            # Add model uncertainty\n",
    "            soc = soc + torch.normal(torch.ones([N, 1]) * self.f_mean, torch.ones([N, 1]) * self.f_std).to(device)\n",
    "\n",
    "            # Bounds\n",
    "            max_test = soc[:, 0] > 1.0\n",
    "            soc[max_test, 0] = 1.0\n",
    "            min_test = soc[:, 0] < 0.0\n",
    "            soc[min_test, 0] = 0.0000000001\n",
    "\n",
    "            # Posterior Evidence\n",
    "            I = torch.ones(N, 1) * current[0, t]\n",
    "            I = I.to(device, torch.float)\n",
    "            scaled_I = apply_scale(I, Current_min, Current_max)\n",
    "            # Estimate Z_p\n",
    "            combined = torch.cat((soc, scaled_I), 1)\n",
    "            Z = torch.sigmoid(self.Z_hl1(combined))\n",
    "            Z = torch.sigmoid(self.Z_hl2(Z))\n",
    "            Z = self.Z_p(Z)\n",
    "\n",
    "            # Estimate posterior V\n",
    "            V = self.VoC(soc) - I*Z\n",
    "\n",
    "            #SMC\n",
    "            W = self.nu * torch.exp(-0.5 * torch.pow((V.to(\"cpu\") - voltage_measured[0, t]) / self.g_std, 2.0))\n",
    "            logW = torch.log(self.nu) - 0.5 * torch.pow((V.to(\"cpu\") - voltage_measured[0, t]) / self.g_std, 2.0)\n",
    "\n",
    "            max_logW = logW.max()\n",
    "            loss_W = torch.exp(logW - max_logW)\n",
    "\n",
    "            if not first:\n",
    "                loss = loss + max_logW + torch.log(torch.sum(loss_W)) - torch.Tensor([np.log(N)])\n",
    "            else:\n",
    "                loss = max_logW + torch.log(torch.sum(loss_W)) - torch.Tensor([np.log(N)])\n",
    "                first = False\n",
    "\n",
    "            # Resampling\n",
    "            soc, W = resample(soc, loss_W)\n",
    "\n",
    "            self.w_hist[:, t] = W[:, 0]\n",
    "            voltage[:, t] = V[:, 0]\n",
    "            soc_hist[:, t] = soc[:, 0]\n",
    "            self.voltage_expected_hist[0, t] = V.transpose(0, 1).mm(W.to(device))\n",
    "            self.soc_expected_hist[0, t] = soc.transpose(0, 1).mm(W.to(device))\n",
    "\n",
    "            self.last_soc = soc.transpose(0, 1).mm(W.to(device))\n",
    "\n",
    "        return loss, voltage, soc_hist\n",
    "    \n",
    "    def SoMPA(self, soc_init, current, voltage_measured, estimation_stop, cut_off_voltage, mc_samples=10000):\n",
    "        loss, voltage, soc_hist = self.forward(soc_init, current, voltage_measured, estimation_stop=estimation_stop)\n",
    "        set_size = current.shape[1] - soc_hist.shape[1]\n",
    "        N = mc_samples\n",
    "        soc = torch.ones((N, 1), dtype=torch.float).to(device)*self.last_soc\n",
    "        voltage_prediction = torch.empty((soc.shape[0], set_size), dtype=torch.float)\n",
    "        soc_prediction = torch.empty((soc.shape[0], set_size), dtype=torch.float)\n",
    "\n",
    "        I = torch.ones(N, 1) * current[0, estimation_stop-1]\n",
    "        I = I.to(device, torch.float)\n",
    "        scaled_I = apply_scale(I, Current_min, Current_max)\n",
    "        scaled_soc = apply_scale(soc, SoC_min, SoC_max)\n",
    "        # Estimate Z_p\n",
    "        combined = torch.cat((scaled_soc, scaled_I), 1)\n",
    "        Z = torch.sigmoid(self.Z_hl1(combined))\n",
    "        Z = torch.sigmoid(self.Z_hl2(Z))\n",
    "        Z = self.Z_p(Z)\n",
    "\n",
    "        # Estimate prior V\n",
    "        V = self.VoC(soc) - I * Z\n",
    "        for t in range(0, set_size):\n",
    "            i = soc_hist.shape[1] + t\n",
    "            # Predict SoC\n",
    "            soc = soc - I * V / E_crit_new * self.E_crit\n",
    "            # Add model uncertainty\n",
    "            soc = soc + torch.normal(torch.ones([N, 1]) * self.f_mean, torch.ones([N, 1]) * self.f_std).to(device)\n",
    "\n",
    "            # Bounds\n",
    "            max_test = soc[:, 0] > 1.0\n",
    "            soc[max_test, 0] = 1.0\n",
    "            min_test = soc[:, 0] < 0.0\n",
    "            soc[min_test, 0] = 0.0000000001\n",
    "\n",
    "            # Posterior Evidence\n",
    "            I = torch.ones(N, 1) * current[0, i]\n",
    "            I = I.to(device, torch.float)\n",
    "            scaled_I = apply_scale(I, Current_min, Current_max)\n",
    "            # Estimate Z_p\n",
    "            combined = torch.cat((soc, scaled_I), 1)\n",
    "            Z = torch.sigmoid(self.Z_hl1(combined))\n",
    "            Z = torch.sigmoid(self.Z_hl2(Z))\n",
    "            Z = self.Z_p(Z)\n",
    "\n",
    "            # Estimate posterior V\n",
    "            V = self.VoC(soc) - I * Z\n",
    "            voltage_prediction[:, t] = V[:, 0]\n",
    "            soc_prediction[:, t] = soc[:, 0]\n",
    "            SoMPA_pdf = None\n",
    "        # Generate SoMPA KDE\n",
    "        from sklearn.neighbors import KernelDensity\n",
    "        test_V = voltage_prediction.numpy().T <= cut_off_voltage\n",
    "        SoMPA = np.zeros_like(test_V.astype(float))\n",
    "        first_past_threshold = np.argmax(test_V, axis=0)[:, np.newaxis] + estimation_stop\n",
    "        std_samples = np.std(first_past_threshold)\n",
    "        SoMPA_base = np.arange(0, current.shape[1])[:, np.newaxis]\n",
    "        log_dens = KernelDensity(kernel='gaussian', bandwidth=1.06*std_samples*np.power(mc_samples, -1/5.0)).fit(first_past_threshold).score_samples(SoMPA_base)\n",
    "        SoMPA_pdf = np.exp(log_dens)\n",
    "\n",
    "        return loss, voltage, soc_hist, voltage_prediction, soc_prediction, SoMPA_pdf, first_past_threshold\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vsmc = RNNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Set = pickle.load(open(\"Battery_Data/degraded_battery_cycles/Test_Degraded_Battery_Set.p\", 'rb'))\n",
    "saved_network = \"./Battery_Data/degraded_battery_cycles/Battery_RNN_from_new_vpf_learn_Ecrit_v1\"\n",
    "parts = 4\n",
    "N = 100\n",
    "estimation_stop, cut_off_voltage = 400, 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3bdca602f68c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m font = {\"figure.titlesize\": 20,\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m\"figure.titleweight\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\"axes.titlesize\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"axes.labelsize\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (20.0, 20.0)\n",
    "font = {\"figure.titlesize\": 20,\n",
    "        \"figure.titleweight\": 'normal',\n",
    "        \"axes.titlesize\" : 20,\n",
    "        \"axes.labelsize\" : 20,\n",
    "        \"lines.linewidth\" : 3,\n",
    "        \"lines.markersize\" : 10,\n",
    "        \"xtick.labelsize\" : 16,\n",
    "        \"ytick.labelsize\" : 16,\n",
    "        'axes.labelweight': 'bold',\n",
    "        'legend.fontsize': 15.0,\n",
    "        'legend.loc': 'upper right'\n",
    "       }\n",
    "for key in font:\n",
    "    matplotlib.rcParams[key] = font[key]\n",
    "saved = \"{0}_part_{1}.mdl\".format(saved_network, parts)\n",
    "with torch.no_grad():\n",
    "    vsmc.load_state_dict(torch.load(saved))\n",
    "    vsmc.to(device)\n",
    "    title = [\"Test Discharge (not used in training)\", \n",
    "             \"Random Discharge 1\", \"Random Discharge 2\", \"Random Discharge 3\"]\n",
    "    for j, set_dict in enumerate(Training_Set):\n",
    "        if j != 0:\n",
    "            state = torch.ones(N, 1) * 1.0\n",
    "            loss, voltage, soc_hist, voltage_prediction, soc_prediction, SoMPA, pass_threshold = vsmc.SoMPA(state,\n",
    "                                                               set_dict['Current'],\n",
    "                                                               set_dict['Voltage'],\n",
    "                                                               estimation_stop,\n",
    "                                                               cut_off_voltage)\n",
    "            seconds = torch.ones_like(vsmc.voltage_expected_hist).numpy()\n",
    "            voltage_expected_hist = vsmc.voltage_expected_hist.numpy()\n",
    "            soc_expected_hist = vsmc.soc_expected_hist.numpy()\n",
    "            current = np.array(set_dict['Current'])\n",
    "            \n",
    "            fig, (ax1, ax3, ax4) = plt.subplots(nrows=3, sharex=True)\n",
    "            \n",
    "            ax4.set_xlabel(\"Seconds\")\n",
    "            ax1.axvline(x=estimation_stop, color='g', linestyle='--', label=\"Prognosis Starts\", linewidth=2.0)\n",
    "            color = 'k'\n",
    "            ax1.set_ylabel(\"Volts\", color=color)\n",
    "            ax1.plot(set_dict['Voltage'].T, linestyle='-', color=color, label=\"Terminal Voltage\")\n",
    "            ax1.plot(voltage_expected_hist.T, '-g', label=\"Estimated Voltage\")\n",
    "            ax1.axhline(y=cut_off_voltage, color='r', linestyle='--', label=\"Cut-off Voltage\", linewidth=2.0)\n",
    "            ax1.tick_params(axis='y', labelcolor=color)\n",
    "            ax1.set_ylim([2.7, 4.2])\n",
    "            \n",
    "            \n",
    "\n",
    "            ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "            color = 'b'\n",
    "            ax2.set_ylabel('SoMPA probabilty', color=color)  # we already handled the x-label with ax1\n",
    "            ax2.fill(np.arange(0, set_dict['Current'].shape[1]), SoMPA, fc=color, alpha=0.9, label='SoMPA')\n",
    "            ax2.tick_params(axis='y', labelcolor=color)\n",
    "            ax2.set_ylim([0, SoMPA.max()*5.0])\n",
    "            ax2.grid(None)\n",
    "            fig.legend(bbox_to_anchor=(0.8, 0.79))\n",
    "\n",
    "            ax3.plot(np.arange(0, estimation_stop), set_dict['Current'].T[:estimation_stop], '-r', label=\"Current Profile\")\n",
    "            ax3.plot(np.arange(estimation_stop, set_dict['Current'].shape[1]), set_dict['Current'].T[estimation_stop:], '-b', label=\"Predicted Profile\")\n",
    "            ax3.axvline(x=estimation_stop, color='g', linestyle='--', label=\"Prognosis Starts\", linewidth=2.0)\n",
    "            ax3.set_ylabel(\"Current\")\n",
    "            ax3.legend()\n",
    "            \n",
    "            ax4.plot(soc_hist.numpy().T, '.b')\n",
    "            ax4.plot([],'.b', label=\"SoC particles\")\n",
    "            ax4.plot(soc_expected_hist.T,'-g', label=\"Estimated State of Charge\")\n",
    "            soc_pred = soc_prediction.numpy().T\n",
    "            for i in range(pass_threshold.shape[0]):\n",
    "                ax4.plot(np.arange(estimation_stop, pass_threshold[i, 0]), soc_pred[:(pass_threshold[i, 0]-estimation_stop), i], '.m')\n",
    "            ax4.plot([], '.m', label=\"SoC prognosis\")\n",
    "            ax4.axvline(x=estimation_stop, color='g', linestyle='--', label=\"Prognosis Starts\", linewidth=2.0)\n",
    "            ax4.legend()\n",
    "            ax4.set_ylabel(\"SoC\")\n",
    "            ax4.set_ylim([0.0, 1.1])\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
